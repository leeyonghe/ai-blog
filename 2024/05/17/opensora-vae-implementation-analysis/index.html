<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

<!-- 기본 SEO 메타 태그 -->
<title>Open-Sora VAE 모델 소스코드 심층 분석: AutoEncoder부터 Discriminator까지 | AI Development Blog</title>
<meta name="description" content="개요Open-Sora의 VAE(Variational AutoEncoder)는 비디오와 이미지를 잠재 공간으로 압축하고 복원하는 핵심 컴포넌트입니다. 이번 포스트에서는 VAE 모델의 소스코드를 완전히 분해하여 각 모듈의 구현 원리와 최적화 기법을 상세히 분석해보겠습니다.VAE 모듈 ...">
<meta name="author" content="David Lee">
<meta name="keywords" content="opensora, vae, autoencoder, discriminator, loss-functions, pytorch, video-compression">

<!-- 정규 URL -->
<link rel="canonical" href="https://leeyonghe.github.io/ai-blog/2024/05/17/opensora-vae-implementation-analysis/">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="article">
<meta property="og:title" content="Open-Sora VAE 모델 소스코드 심층 분석: AutoEncoder부터 Discriminator까지">
<meta property="og:description" content="개요Open-Sora의 VAE(Variational AutoEncoder)는 비디오와 이미지를 잠재 공간으로 압축하고 복원하는 핵심 컴포넌트입니다. 이번 포스트에서는 VAE 모델의 소스코드를 완전히 분해하여 각 모듈의 구현 원리와 최적화 기법을 상세히 분석해보겠습니다.VAE 모듈 ...">
<meta property="og:url" content="https://leeyonghe.github.io/ai-blog/2024/05/17/opensora-vae-implementation-analysis/">
<meta property="og:site_name" content="AI Development Blog">

<meta property="og:image" content="https://leeyonghe.github.io/ai-blog/assets/images/opensora-vae-analysis.png">

<meta property="og:locale" content="ko_KR">

<!-- Twitter Card -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="Open-Sora VAE 모델 소스코드 심층 분석: AutoEncoder부터 Discriminator까지">
<meta name="twitter:description" content="개요Open-Sora의 VAE(Variational AutoEncoder)는 비디오와 이미지를 잠재 공간으로 압축하고 복원하는 핵심 컴포넌트입니다. 이번 포스트에서는 VAE 모델의 소스코드를 완전히 분해하여 각 모듈의 구현 원리와 최적화 기법을 상세히 분석해보겠습니다.VAE 모듈 ...">

<meta name="twitter:image" content="https://leeyonghe.github.io/ai-blog/assets/images/opensora-vae-analysis.png">



<!-- 검색 엔진 인증 메타 태그 -->



<!-- 언어 및 지역 설정 -->
<meta name="language" content="ko">
<meta name="geo.region" content="KR">
<meta name="geo.country" content="KR">

<!-- 추가 SEO 메타 태그 -->
<meta name="robots" content="index, follow">
<meta name="revisit-after" content="7 days">
<meta name="rating" content="general">

<!-- RSS 피드 -->
<link rel="alternate" type="application/rss+xml" title="AI Development Blog" href="https://leeyonghe.github.io/ai-blog/feed.xml">

<!-- 구조화된 데이터 (JSON-LD) -->
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Blog",
  "name": "AI Development Blog",
  "description": "AI 개발 및 프레임워크 분석을 다루는 기술 블로그입니다. Rust, Python, AI/ML 프로젝트의 심층 분석과 실무 경험을 공유합니다.
",
  "url": "https://leeyonghe.github.io/ai-blog",
  "author": {
    "@type": "Person",
    "name": "David Lee",
    "email": "lee.yonghee.dev@gmail.com"
  },
  "inLanguage": "ko",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "https://leeyonghe.github.io/ai-blog/search?q={search_term_string}",
    "query-input": "required name=search_term_string"
  }
}
</script>

<!-- 개별 포스트 구조화된 데이터 -->

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Open-Sora VAE 모델 소스코드 심층 분석: AutoEncoder부터 Discriminator까지",
  "description": "개요

Open-Sora의 VAE(Variational AutoEncoder)는 비디오와 이미지를 잠재 공간으로 압축하고 복원하는 핵심 컴포넌트입니다. 이번 포스트에서는 VAE 모델의 소스코드를 완전히 분해하여 각 모듈의 구현 원리와 최적화 기법을 상세히 분석해보겠습니다.

VAE...",
  "image": "https://leeyonghe.github.io/ai-blog/assets/images/opensora-vae-analysis.png",
  "author": {
    "@type": "Person",
    "name": "David Lee"
  },
  "publisher": {
    "@type": "Organization",
    "name": "AI Development Blog",
    "logo": {
      "@type": "ImageObject",
      "url": ""
    }
  },
  "datePublished": "2024-05-17T06:00:00+00:00",
  "dateModified": "2024-05-17T06:00:00+00:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://leeyonghe.github.io/ai-blog/2024/05/17/opensora-vae-implementation-analysis/"
  },
  "url": "https://leeyonghe.github.io/ai-blog/2024/05/17/opensora-vae-implementation-analysis/",
  "inLanguage": "ko",
  "keywords": ["opensora","vae","autoencoder","discriminator","loss-functions","pytorch","video-compression"],
  "articleSection": ["AI","Deep Learning","Computer Vision","Source Code"]
}
</script>

<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">
<link rel="stylesheet" href="/ai-blog/assets/css/style.css">
<link rel="stylesheet" href="/ai-blog/assets/css/post-detail.css">
<style>
/* Post Detail Page Styling */
.post-container article {
  background: #fff;
  border-radius: 12px;
  box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
  padding: 40px;
  margin: 30px auto;
  max-width: 800px;
}

@media screen and (max-width: 768px) {
  .post-container article {
    margin: 20px;
    padding: 25px;
    border-radius: 8px;
  }
}

.post-container article .post-header {
  border-bottom: 2px solid #f5f5f5;
  padding-bottom: 25px;
  margin-bottom: 30px;
}

.post-container article .post-header .post-title {
  font-size: 2.2em;
  font-weight: 700;
  color: #2c3e50;
  line-height: 1.3;
  margin-bottom: 15px;
}

@media screen and (max-width: 768px) {
  .post-container article .post-header .post-title {
    font-size: 1.8em;
  }
}

.post-container article .post-header .post-meta {
  display: flex;
  align-items: center;
  gap: 20px;
  flex-wrap: wrap;
}

.post-container article .post-header .post-meta .post-date {
  display: flex;
  align-items: center;
  color: #666;
  font-size: 0.9em;
}

.post-container article .post-header .post-meta .post-date i {
  margin-right: 8px;
  color: #888;
}

.post-container article .post-header .post-meta .post-categories-wrapper {
  display: flex;
  align-items: center;
}

.post-container article .post-header .post-meta .post-categories-wrapper i {
  margin-right: 8px;
  color: #888;
}

.post-container article .post-header .post-meta .post-categories-wrapper .post-categories {
  display: flex;
  gap: 8px;
  list-style: none;
  margin: 0;
  padding: 0;
}

.post-container article .post-header .post-meta .post-categories-wrapper .post-categories li {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  padding: 4px 12px;
  border-radius: 20px;
  font-size: 0.8em;
  font-weight: 500;
  text-transform: capitalize;
}

.post-container article .post-content {
  font-size: 1.1em;
  line-height: 1.8;
  color: #333;
}

.post-container article .post-content p {
  margin-bottom: 1.2em;
}

.post-container article .post-content h1,
.post-container article .post-content h2,
.post-container article .post-content h3,
.post-container article .post-content h4,
.post-container article .post-content h5,
.post-container article .post-content h6 {
  color: #2c3e50;
  margin: 1.5em 0 0.8em 0;
  font-weight: 600;
}

.post-container article .post-content h2 {
  font-size: 1.8em;
  border-bottom: 2px solid #3498db;
  padding-bottom: 10px;
}

.post-container article .post-content h3 {
  font-size: 1.5em;
  color: #34495e;
}

.post-container article .post-content code {
  background: #f8f9fa;
  padding: 2px 6px;
  border-radius: 4px;
  font-size: 0.9em;
  color: #e74c3c;
}

.post-container article .post-content pre {
  background: #f8f9fa;
  border: 1px solid #e9ecef;
  border-radius: 6px;
  padding: 15px;
  overflow-x: auto;
  margin: 1.5em 0;
}

.post-container article .post-content pre code {
  background: none;
  color: #333;
  padding: 0;
}

.post-container article .post-content blockquote {
  border-left: 4px solid #3498db;
  background: #f8f9fa;
  padding: 15px 20px;
  margin: 1.5em 0;
  font-style: italic;
  color: #555;
}

.post-container article .post-content img {
  max-width: 100%;
  height: auto;
  border-radius: 8px;
  margin: 1.5em 0;
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
}

.post-container article .post-content ul,
.post-container article .post-content ol {
  padding-left: 1.5em;
  margin-bottom: 1.2em;
}

.post-container article .post-content ul li,
.post-container article .post-content ol li {
  margin-bottom: 0.5em;
}

.post-container article .post-content a {
  color: #3498db;
  text-decoration: none;
  border-bottom: 1px solid transparent;
  transition: all 0.3s ease;
}

.post-container article .post-content a:hover {
  border-bottom-color: #3498db;
}

.post-container article .post-footer {
  border-top: 2px solid #f5f5f5;
  padding-top: 25px;
  margin-top: 40px;
}

.post-container article .post-footer .post-navigation {
  display: flex;
  justify-content: space-between;
  align-items: center;
  gap: 20px;
}

@media screen and (max-width: 768px) {
  .post-container article .post-footer .post-navigation {
    flex-direction: column;
    gap: 15px;
  }
}

.post-container article .post-footer .post-navigation .nav-previous,
.post-container article .post-footer .post-navigation .nav-next {
  flex: 1;
}

.post-container article .post-footer .post-navigation .nav-previous a,
.post-container article .post-footer .post-navigation .nav-next a {
  display: flex;
  align-items: center;
  padding: 15px 20px;
  background: #f8f9fa;
  border-radius: 8px;
  text-decoration: none;
  color: #333;
  transition: all 0.3s ease;
  border: 2px solid transparent;
}

.post-container article .post-footer .post-navigation .nav-previous a:hover,
.post-container article .post-footer .post-navigation .nav-next a:hover {
  background: #e9ecef;
  border-color: #3498db;
  transform: translateY(-2px);
}

.post-container article .post-footer .post-navigation .nav-previous a i,
.post-container article .post-footer .post-navigation .nav-next a i {
  color: #3498db;
  margin: 0 8px;
}

.post-container article .post-footer .post-navigation .nav-previous a .nav-title,
.post-container article .post-footer .post-navigation .nav-next a .nav-title {
  font-weight: 500;
}

.post-container article .post-footer .post-navigation .nav-previous a {
  justify-content: flex-start;
}

.post-container article .post-footer .post-navigation .nav-next a {
  justify-content: flex-end;
  text-align: right;
}
</style>
<title>Open-Sora VAE 모델 소스코드 심층 분석: AutoEncoder부터 Discriminator까지</title>

<script type="text/javascript" src="/ai-blog/assets/js/darkmode.js"></script>


<!-- Mermaid Diagram Support -->
<script type="text/javascript" src="/ai-blog/assets/js/mermaid-init.js"></script>
<link rel="stylesheet" href="/ai-blog/assets/css/network-diagrams.css">
<style>
/* Mermaid diagram styling - Network optimized */
.mermaid {
  text-align: center;
  margin: 2em 0;
  padding: 1.5em;
  background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
  border: 2px solid #e2e8f0;
  border-radius: 12px;
  box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
  overflow-x: auto;
  position: relative;
}

.mermaid::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  height: 4px;
  background: linear-gradient(90deg, #3b82f6, #1d4ed8, #1e40af);
  border-radius: 12px 12px 0 0;
}

.mermaid svg {
  max-width: 100%;
  height: auto;
  filter: drop-shadow(0 2px 4px rgba(0, 0, 0, 0.1));
}

/* Network diagram specific styling */
.mermaid .node rect,
.mermaid .node circle,
.mermaid .node ellipse,
.mermaid .node polygon {
  stroke-width: 2px;
  filter: drop-shadow(0 1px 3px rgba(0, 0, 0, 0.12));
}

.mermaid .edgePath path {
  stroke-width: 2px;
  filter: drop-shadow(0 1px 2px rgba(0, 0, 0, 0.1));
}

.mermaid .cluster rect {
  stroke-width: 2px;
  stroke-dasharray: 5,5;
  opacity: 0.9;
}

/* Enhanced error styling */
.mermaid-error {
  color: #dc2626;
  background: linear-gradient(135deg, #fef2f2 0%, #fee2e2 100%);
  border: 2px solid #fca5a5;
  border-radius: 12px;
  padding: 1.5em;
  text-align: center;
  font-style: italic;
  font-weight: 500;
  box-shadow: 0 4px 20px rgba(220, 38, 38, 0.1);
}

.mermaid-error::before {
  content: '⚠️ ';
  font-size: 1.2em;
  margin-right: 0.5em;
}

/* Loading animation */
.mermaid.loading {
  min-height: 200px;
  background: linear-gradient(
    90deg,
    #f1f5f9 25%,
    #e2e8f0 50%,
    #f1f5f9 75%
  );
  background-size: 200% 100%;
  animation: shimmer 2s infinite;
}

@keyframes shimmer {
  0% {
    background-position: -200% 0;
  }
  100% {
    background-position: 200% 0;
  }
}

/* Responsive Mermaid diagrams */
@media (max-width: 768px) {
  .mermaid {
    font-size: 0.85em;
    padding: 1em;
    margin: 1.5em 0;
    border-radius: 8px;
  }

  .mermaid svg {
    transform: scale(0.9);
    transform-origin: center;
  }
}

@media (max-width: 480px) {
  .mermaid {
    font-size: 0.75em;
    padding: 0.8em;
    margin: 1em 0;
  }

  .mermaid svg {
    transform: scale(0.8);
  }
}

/* Dark mode support */
@media (prefers-color-scheme: dark) {
  .mermaid {
    background: linear-gradient(135deg, #1e293b 0%, #334155 100%);
    border-color: #475569;
    color: #f1f5f9;
  }

  .mermaid::before {
    background: linear-gradient(90deg, #60a5fa, #3b82f6, #2563eb);
  }

  .mermaid-error {
    background: linear-gradient(135deg, #451a03 0%, #7c2d12 100%);
    border-color: #dc2626;
    color: #fef2f2;
  }
}

/* Print styles */
@media print {
  .mermaid {
    background: white !important;
    border: 1px solid #ccc !important;
    box-shadow: none !important;
    break-inside: avoid;
  }

  .mermaid::before {
    display: none !important;
  }
}
</style>
</head><body>
  <main class="container">
    <section class="about">
      <div class="about-header condensed">
      <div class="about-title">
      <a href="/ai-blog/">
        
        <img src="/ai-blog/assets/portfolio.png" alt="David Lee" />
        
      </a>
      <h2 id="title">
        <a href="/ai-blog/">David Lee</a>
      </h2>
      </div><p class="tagline">Developer</p></div>
      
      <ul class="social about-footer condensed"><a href="https://github.com/leeyonghe" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://www.linkedin.com/in/lee-yong-hee-18912454/" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><!----></ul><p class="about-footer condensed">&copy;
        2025</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </section>
    <section class="content">
      <style>
/* Post Detail Page Styling - Direct Inline */
.post-container article {
  background: #fff !important;
  border: none !important;
  border-top: none !important;
  border-right: none !important;
  border-bottom: none !important;
  border-left: none !important;
  border-width: 0 !important;
  border-style: none !important;
  outline: none !important;
  border-radius: 12px !important;
  box-shadow: none !important;
  padding: 40px !important;
  margin: 30px auto !important;
  max-width: 800px !important;
}

.post-container article .post-header .post-title {
  font-size: 2.2em !important;
  font-weight: 700 !important;
  color: #2c3e50 !important;
  line-height: 1.3 !important;
}

.post-container article .post-header {
  border-bottom: none !important;
  padding-bottom: 25px !important;
  margin-bottom: 30px !important;
}

.post-container article .post-content {
  font-size: 1.1em !important;
  line-height: 1.8 !important;
  color: #333 !important;
}

.post-container article .post-content h2 {
  font-size: 1.8em !important;
  border-bottom: none !important;
  padding-bottom: 10px !important;
  color: #2c3e50 !important;
}

.post-container article .post-header .post-meta .post-categories li {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
  color: white !important;
  padding: 4px 12px !important;
  border-radius: 20px !important;
  font-size: 0.8em !important;
  list-style: none !important;
  display: inline-block !important;
  margin-right: 8px !important;
}

.post-container article .post-footer {
  border-top: none !important;
  padding-top: 25px !important;
  margin-top: 40px !important;
}

/* 모든 border와 box-shadow 강제 제거 */
.post-container article *,
.post-container article *::before,
.post-container article *::after {
  border: none !important;
  border-top: none !important;
  border-right: none !important;
  border-bottom: none !important;
  border-left: none !important;
  border-width: 0 !important;
  border-style: none !important;
  outline: none !important;
  box-shadow: none !important;
}

/* 코드 블록과 pre 태그도 border, box-shadow 제거 */
.post-container article pre,
.post-container article code,
.post-container article .highlight,
.post-container article .highlighter-rouge {
  border: none !important;
  outline: none !important;
  box-shadow: none !important;
}
</style><div class="post-container">
  <article>
    <header class="post-header">
    <h1 class="post-title">Open-Sora VAE 모델 소스코드 심층 분석: AutoEncoder부터 Discriminator까지</h1>
    <div class="post-meta">
      <div class="post-date">
        <i class="icon-calendar"></i>
        <time datetime="2024-05-17T06:00:00+00:00">May 17, 2024</time>
      </div><div class="post-categories-wrapper">
        <i class="icon-tag"></i>
        <ul class="post-categories"><li>AI</li><li>Deep Learning</li><li>Computer Vision</li><li>Source Code</li></ul>
      </div></div>
  </header>

  <div class="post-content">
    <h2 id="개요">개요</h2>

<p>Open-Sora의 VAE(Variational AutoEncoder)는 비디오와 이미지를 잠재 공간으로 압축하고 복원하는 핵심 컴포넌트입니다. 이번 포스트에서는 VAE 모델의 소스코드를 완전히 분해하여 각 모듈의 구현 원리와 최적화 기법을 상세히 분석해보겠습니다.</p>

<h2 id="vae-모듈-구조-개요">VAE 모듈 구조 개요</h2>

<div class="mermaid">
graph TB
    subgraph "Open-Sora VAE Architecture"
        A[Input Video/Image] --&gt; B[AutoEncoder 2D]
        
        subgraph "Encoder Path"
            B --&gt; C[Initial Conv]
            C --&gt; D[ResNet Blocks]
            D --&gt; E[Downsample Layers]
            E --&gt; F[Latent Distribution]
            F --&gt; G[Reparameterization]
        end
        
        subgraph "Latent Space"
            G --&gt; H[Latent Representation]
            H --&gt; I[z_channels: 4]
            I --&gt; J[Scale: 0.18215]
        end
        
        subgraph "Decoder Path"
            H --&gt; K[Initial Processing]
            K --&gt; L[Upsample Layers]
            L --&gt; M[ResNet Blocks]
            M --&gt; N[Final Conv]
            N --&gt; O[Reconstructed Output]
        end
        
        subgraph "Discriminator Network"
            A --&gt; P[3D PatchGAN Discriminator]
            O --&gt; P
            P --&gt; Q[Real/Fake Classification]
        end
        
        subgraph "Loss Functions"
            R[Reconstruction Loss]
            S[KL Divergence]
            T[Perceptual Loss]
            U[Adversarial Loss]
            
            O -.-&gt; R
            F -.-&gt; S
            O -.-&gt; T
            Q -.-&gt; U
        end
    end
    
    style A fill:#e1f5fe
    style H fill:#ffcdd2
    style O fill:#c8e6c9
    style P fill:#fff3e0
</div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>opensora/models/vae/
├── autoencoder_2d.py    # 2D AutoEncoder 구현
├── discriminator.py     # 3D PatchGAN Discriminator
├── losses.py           # 손실 함수들 (Perceptual, Adversarial)
├── lpips.py            # LPIPS 지각적 손실
├── utils.py            # 유틸리티 (Gaussian 분포, Conv3D 최적화)
└── tensor_parallel.py  # 텐서 병렬화 최적화
</code></pre></div></div>

<h2 id="1-autoencoder-2d-구현-분석">1. AutoEncoder 2D 구현 분석</h2>

<h3 id="설정-구조-autoencoderconfig">설정 구조 (AutoEncoderConfig)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">@</span><span class="n">dataclass</span>
<span class="k">class</span> <span class="nc">AutoEncoderConfig</span><span class="p">:</span>
    <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="bp">None</span>    <span class="c1"># 사전 훈련된 모델 경로
</span>    <span class="n">cache_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="bp">None</span>          <span class="c1"># 캐시 디렉토리
</span>    <span class="n">resolution</span><span class="p">:</span> <span class="nb">int</span>                <span class="c1"># 해상도 (256, 512, 768 등)
</span>    <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span>               <span class="c1"># 입력 채널 수 (RGB: 3)
</span>    <span class="n">ch</span><span class="p">:</span> <span class="nb">int</span>                        <span class="c1"># 기본 채널 수 (128)
</span>    <span class="n">out_ch</span><span class="p">:</span> <span class="nb">int</span>                    <span class="c1"># 출력 채널 수 (3)
</span>    <span class="n">ch_mult</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>            <span class="c1"># 채널 배수 [1, 2, 4, 4]
</span>    <span class="n">num_res_blocks</span><span class="p">:</span> <span class="nb">int</span>           <span class="c1"># 잔차 블록 수 (2)
</span>    <span class="n">z_channels</span><span class="p">:</span> <span class="nb">int</span>               <span class="c1"># 잠재 공간 채널 수 (4)
</span>    <span class="n">scale_factor</span><span class="p">:</span> <span class="nb">float</span>           <span class="c1"># 스케일 팩터 (0.18215)
</span>    <span class="n">shift_factor</span><span class="p">:</span> <span class="nb">float</span>           <span class="c1"># 시프트 팩터 (0.0)
</span>    <span class="n">sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span>           <span class="c1"># 샘플링 여부
</span></code></pre></div></div>

<p><strong>핵심 파라미터 의미:</strong></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">ch_mult: [1, 2, 4, 4]</code>: 인코더에서 128→256→512→512 채널로 증가</li>
  <li><code class="language-plaintext highlighter-rouge">z_channels: 4</code>: 잠재 공간을 4채널로 압축 (RGB 3채널보다 효율적)</li>
  <li><code class="language-plaintext highlighter-rouge">scale_factor: 0.18215</code>: Stable Diffusion 표준 스케일링</li>
</ul>

<h3 id="attention-block-구현">Attention Block 구현</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AttnBlock</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="c1"># Group Normalization: 배치 크기에 무관
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">num_groups</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        
        <span class="c1"># Q, K, V 프로젝션 (1x1 Convolution)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># 출력 프로젝션
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">proj_out</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">attention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h_</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">h_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">h_</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">q</span><span class="p">(</span><span class="n">h_</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">k</span><span class="p">(</span><span class="n">h_</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">(</span><span class="n">h_</span><span class="p">)</span>
        
        <span class="c1"># Spatial Attention 계산
</span>        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="s">"b c h w -&gt; b 1 (h w) c"</span><span class="p">).</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="s">"b c h w -&gt; b 1 (h w) c"</span><span class="p">).</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="s">"b c h w -&gt; b 1 (h w) c"</span><span class="p">).</span><span class="n">contiguous</span><span class="p">()</span>
        
        <span class="c1"># PyTorch 네이티브 Scaled Dot-Product Attention 사용
</span>        <span class="n">h_</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">h_</span><span class="p">,</span> <span class="s">"b 1 (h w) c -&gt; b c h w"</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># 잔차 연결
</span>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">proj_out</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div></div>

<p><strong>핵심 최적화:</strong></p>
<ul>
  <li><strong>einops.rearrange</strong>: 효율적인 텐서 재구성</li>
  <li><strong>scaled_dot_product_attention</strong>: PyTorch 네이티브 최적화된 어텐션</li>
  <li><strong>Group Normalization</strong>: 배치 크기 변화에 강건</li>
</ul>

<h3 id="resnet-block-구현">ResNet Block 구현</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ResnetBlock</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="n">out_channels</span> <span class="o">=</span> <span class="n">in_channels</span> <span class="k">if</span> <span class="n">out_channels</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">out_channels</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>

        <span class="c1"># 첫 번째 컨볼루션 경로
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">num_groups</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># 두 번째 컨볼루션 경로
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">num_groups</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Skip Connection (채널 수가 다른 경우)
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">!=</span> <span class="bp">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">nin_shortcut</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">x</span>
        
        <span class="c1"># 첫 번째 경로: Norm → SiLU → Conv
</span>        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">swish</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>  <span class="c1"># SiLU 활성화 함수
</span>        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="c1"># 두 번째 경로: Norm → SiLU → Conv
</span>        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">swish</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="c1"># Skip Connection 처리
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">!=</span> <span class="bp">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">nin_shortcut</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">h</span>  <span class="c1"># 잔차 연결
</span></code></pre></div></div>

<p><strong>설계 원칙:</strong></p>
<ul>
  <li><strong>SiLU(Swish) 활성화</strong>: ReLU보다 부드러운 그래디언트</li>
  <li><strong>Group Normalization</strong>: 안정적인 훈련</li>
  <li><strong>잔차 연결</strong>: 깊은 네트워크에서 그래디언트 소실 방지</li>
</ul>

<h2 id="2-3d-discriminator-구현-분석">2. 3D Discriminator 구현 분석</h2>

<h3 id="nlayerdiscriminator3d-구조">NLayerDiscriminator3D 구조</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">NLayerDiscriminator3D</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""3D PatchGAN Discriminator - Pix2Pix의 3D 확장"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_nc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>           <span class="c1"># 입력 채널 수
</span>        <span class="n">ndf</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>              <span class="c1"># 첫 번째 레이어 필터 수
</span>        <span class="n">n_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>          <span class="c1"># 컨볼루션 레이어 수
</span>        <span class="n">norm_layer</span><span class="o">=</span><span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>  <span class="c1"># 정규화 레이어
</span>        <span class="n">conv_cls</span><span class="o">=</span><span class="s">"conv3d"</span><span class="p">,</span>   <span class="c1"># 컨볼루션 타입
</span>        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.30</span><span class="p">,</span>        <span class="c1"># 드롭아웃 확률
</span>    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NLayerDiscriminator3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">conv_cls</span> <span class="o">==</span> <span class="s">"conv3d"</span>  <span class="c1"># 3D 컨볼루션만 지원
</span></code></pre></div></div>

<p><strong>3D PatchGAN의 장점:</strong></p>
<ul>
  <li><strong>시공간 일관성</strong>: 시간축과 공간축을 동시에 판별</li>
  <li><strong>계산 효율성</strong>: 전체 비디오보다 패치 단위로 처리</li>
  <li><strong>세밀한 판별</strong>: 지역적 특징과 전역적 특징 모두 고려</li>
</ul>

<h3 id="가중치-초기화-전략">가중치 초기화 전략</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">weights_init</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="s">"""표준 가중치 초기화"""</span>
    <span class="n">classname</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span>
    <span class="k">if</span> <span class="n">classname</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">"Conv"</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>  <span class="c1"># 가우시안 초기화
</span>    <span class="k">elif</span> <span class="n">classname</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">"BatchNorm"</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>  <span class="c1"># BatchNorm 스케일
</span>        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>          <span class="c1"># 편향 0으로 초기화
</span>
<span class="k">def</span> <span class="nf">weights_init_conv</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="s">"""컨볼루션 특화 초기화"""</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s">"conv"</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">conv</span>
    <span class="n">classname</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span>
    <span class="k">if</span> <span class="n">classname</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">"Conv"</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>  <span class="c1"># DCGAN 스타일
</span>    <span class="k">elif</span> <span class="n">classname</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">"BatchNorm"</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>초기화 철학:</strong></p>
<ul>
  <li><strong>DCGAN 스타일</strong>: 0.02 표준편차의 가우시안 분포</li>
  <li><strong>안정적 훈련</strong>: BatchNorm 파라미터 적절한 초기화</li>
  <li><strong>그래디언트 흐름</strong>: 초기 가중치로 훈련 안정성 확보</li>
</ul>

<h2 id="3-손실-함수-구현-분석">3. 손실 함수 구현 분석</h2>

<h3 id="adversarial-loss-함수들">Adversarial Loss 함수들</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">hinge_d_loss</span><span class="p">(</span><span class="n">logits_real</span><span class="p">,</span> <span class="n">logits_fake</span><span class="p">):</span>
    <span class="s">"""Hinge Loss for Discriminator"""</span>
    <span class="n">loss_real</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">logits_real</span><span class="p">))</span>  <span class="c1"># max(0, 1-D(real))
</span>    <span class="n">loss_fake</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">logits_fake</span><span class="p">))</span>  <span class="c1"># max(0, 1+D(fake))
</span>    <span class="n">d_loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">loss_real</span> <span class="o">+</span> <span class="n">loss_fake</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d_loss</span>

<span class="k">def</span> <span class="nf">vanilla_d_loss</span><span class="p">(</span><span class="n">logits_real</span><span class="p">,</span> <span class="n">logits_fake</span><span class="p">):</span>
    <span class="s">"""Vanilla GAN Loss (Log-likelihood)"""</span>
    <span class="n">d_loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="o">-</span><span class="n">logits_real</span><span class="p">))</span> <span class="o">+</span>  <span class="c1"># -log(sigmoid(D(real)))
</span>        <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">logits_fake</span><span class="p">))</span>     <span class="c1"># -log(1-sigmoid(D(fake)))
</span>    <span class="p">)</span>
    <span class="k">return</span> <span class="n">d_loss</span>

<span class="k">def</span> <span class="nf">wgan_gp_loss</span><span class="p">(</span><span class="n">logits_real</span><span class="p">,</span> <span class="n">logits_fake</span><span class="p">):</span>
    <span class="s">"""Wasserstein GAN Loss"""</span>
    <span class="n">d_loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">logits_real</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">logits_fake</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>  <span class="c1"># Earth Mover Distance
</span>    <span class="k">return</span> <span class="n">d_loss</span>
</code></pre></div></div>

<p><strong>손실 함수 비교:</strong></p>

<table>
  <thead>
    <tr>
      <th>손실 함수</th>
      <th>안정성</th>
      <th>품질</th>
      <th>수렴 속도</th>
      <th>특징</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Hinge Loss</strong></td>
      <td>⭐⭐⭐⭐⭐</td>
      <td>⭐⭐⭐⭐</td>
      <td>⭐⭐⭐</td>
      <td>마진 기반, 안정적</td>
    </tr>
    <tr>
      <td><strong>Vanilla GAN</strong></td>
      <td>⭐⭐</td>
      <td>⭐⭐⭐</td>
      <td>⭐⭐⭐⭐</td>
      <td>원본 GAN, 모드 붕괴 위험</td>
    </tr>
    <tr>
      <td><strong>WGAN-GP</strong></td>
      <td>⭐⭐⭐⭐</td>
      <td>⭐⭐⭐⭐⭐</td>
      <td>⭐⭐</td>
      <td>립시츠 제약, 고품질</td>
    </tr>
  </tbody>
</table>

<h3 id="지각적-손실-perceptual-loss">지각적 손실 (Perceptual Loss)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">l1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="s">"""L1 거리 (Manhattan Distance)"""</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">l2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="s">"""L2 거리 (Euclidean Distance)"""</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nb">pow</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">adopt_weight</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
    <span class="s">"""훈련 단계에 따른 가중치 조정"""</span>
    <span class="k">if</span> <span class="n">global_step</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">weight</span>
</code></pre></div></div>

<h3 id="양자화-품질-측정">양자화 품질 측정</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">measure_perplexity</span><span class="p">(</span><span class="n">predicted_indices</span><span class="p">,</span> <span class="n">n_embed</span><span class="p">):</span>
    <span class="s">"""Vector Quantization 품질 측정"""</span>
    <span class="c1"># 원-핫 인코딩으로 클러스터 사용 빈도 계산
</span>    <span class="n">encodings</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">predicted_indices</span><span class="p">,</span> <span class="n">n_embed</span><span class="p">).</span><span class="nb">float</span><span class="p">().</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_embed</span><span class="p">)</span>
    <span class="n">avg_probs</span> <span class="o">=</span> <span class="n">encodings</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># 퍼플렉시티 계산: exp(-sum(p * log(p)))
</span>    <span class="n">perplexity</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">avg_probs</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">avg_probs</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)).</span><span class="nb">sum</span><span class="p">()).</span><span class="n">exp</span><span class="p">()</span>
    
    <span class="c1"># 실제 사용된 클러스터 수
</span>    <span class="n">cluster_use</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">avg_probs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">perplexity</span><span class="p">,</span> <span class="n">cluster_use</span>
</code></pre></div></div>

<p><strong>퍼플렉시티의 의미:</strong></p>
<ul>
  <li><strong>높은 퍼플렉시티</strong>: 모든 클러스터가 균등하게 사용됨 (좋음)</li>
  <li><strong>낮은 퍼플렉시티</strong>: 일부 클러스터만 사용됨 (코드북 붕괴)</li>
  <li><strong>이상적 값</strong>: <code class="language-plaintext highlighter-rouge">n_embed</code>와 같을 때 완벽한 균등 사용</li>
</ul>

<h2 id="4-메모리-최적화-유틸리티-분석">4. 메모리 최적화 유틸리티 분석</h2>

<h3 id="가우시안-분포-처리">가우시안 분포 처리</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DiagonalGaussianDistribution</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="s">"""대각 가우시안 분포 구현"""</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="n">parameters</span>
        
        <span class="c1"># 평균과 로그 분산 분리
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">mean</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">logvar</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># 수치 안정성을 위한 클램핑
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">logvar</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">logvar</span><span class="p">,</span> <span class="o">-</span><span class="mf">30.0</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="n">deterministic</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">logvar</span><span class="p">)</span>  <span class="c1"># std = exp(0.5 * logvar)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">logvar</span><span class="p">)</span>        <span class="c1"># var = exp(logvar)
</span>        
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">deterministic</span><span class="p">:</span>
            <span class="c1"># 결정적 모드에서는 분산 0
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">var</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mean</span><span class="p">).</span><span class="n">to</span><span class="p">(</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">parameters</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">mean</span><span class="p">.</span><span class="n">dtype</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""재매개화 트릭으로 샘플링"""</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mean</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">std</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mean</span><span class="p">.</span><span class="n">shape</span><span class="p">).</span><span class="n">to</span><span class="p">(</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">parameters</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">mean</span><span class="p">.</span><span class="n">dtype</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">kl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="s">"""KL Divergence 계산"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">deterministic</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">])</span>
        
        <span class="k">if</span> <span class="n">other</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>  <span class="c1"># 표준 정규분포와의 KL
</span>            <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span>
                <span class="n">torch</span><span class="p">.</span><span class="nb">pow</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mean</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">var</span> <span class="o">-</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">logvar</span><span class="p">,</span> 
                <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
            <span class="p">).</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># 다른 가우시안과의 KL
</span>            <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span>
                <span class="n">torch</span><span class="p">.</span><span class="nb">pow</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mean</span> <span class="o">-</span> <span class="n">other</span><span class="p">.</span><span class="n">mean</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">other</span><span class="p">.</span><span class="n">var</span> <span class="o">+</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">var</span> <span class="o">/</span> <span class="n">other</span><span class="p">.</span><span class="n">var</span> <span class="o">-</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">logvar</span> <span class="o">+</span> <span class="n">other</span><span class="p">.</span><span class="n">logvar</span><span class="p">,</span>
                <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
            <span class="p">).</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""최빈값 (평균) 반환"""</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">mean</span>
</code></pre></div></div>

<p><strong>재매개화 트릭 (Reparameterization Trick):</strong></p>
<ul>
  <li><strong>목적</strong>: 역전파가 가능한 확률적 샘플링</li>
  <li><strong>수식</strong>: <code class="language-plaintext highlighter-rouge">z = μ + σ ⊙ ε</code> (ε ~ N(0,1))</li>
  <li><strong>장점</strong>: 그래디언트가 μ와 σ를 통해 흐를 수 있음</li>
</ul>

<h3 id="메모리-효율적-conv3d">메모리 효율적 Conv3D</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ChannelChunkConv3D</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Conv3d</span><span class="p">):</span>
    <span class="s">"""메모리 제한을 고려한 청크 기반 3D 컨볼루션"""</span>
    <span class="n">CONV3D_NUMEL_LIMIT</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">31</span>  <span class="c1"># 2GB 제한
</span>
    <span class="k">def</span> <span class="nf">_get_output_numel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="s">"""출력 텐서 크기 계산"""</span>
        <span class="n">numel</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">out_channels</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
            <span class="n">numel</span> <span class="o">*=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># 배치 크기
</span>        
        <span class="c1"># 각 차원의 출력 크기 계산
</span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:]):</span>
            <span class="n">d_out</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">floor</span><span class="p">(</span>
                <span class="p">(</span><span class="n">d</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">padding</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">dilation</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> 
                <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">stride</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="p">)</span>
            <span class="n">numel</span> <span class="o">*=</span> <span class="n">d_out</span>
        <span class="k">return</span> <span class="n">numel</span>

    <span class="k">def</span> <span class="nf">_get_n_chunks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">numel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="s">"""필요한 청크 수 계산"""</span>
        <span class="n">n_chunks</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">numel</span> <span class="o">/</span> <span class="n">ChannelChunkConv3D</span><span class="p">.</span><span class="n">CONV3D_NUMEL_LIMIT</span><span class="p">)</span>
        <span class="n">n_chunks</span> <span class="o">=</span> <span class="n">ceil_to_divisible</span><span class="p">(</span><span class="n">n_chunks</span><span class="p">,</span> <span class="n">n_channels</span><span class="p">)</span>  <span class="c1"># 채널 수로 나누어떨어지게
</span>        <span class="k">return</span> <span class="n">n_chunks</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># 메모리 제한 체크
</span>        <span class="k">if</span> <span class="nb">input</span><span class="p">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">//</span> <span class="nb">input</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">ChannelChunkConv3D</span><span class="p">.</span><span class="n">CONV3D_NUMEL_LIMIT</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">().</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>  <span class="c1"># 표준 컨볼루션 사용
</span>        
        <span class="c1"># 청크 기반 처리
</span>        <span class="n">n_in_chunks</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_n_chunks</span><span class="p">(</span><span class="nb">input</span><span class="p">.</span><span class="n">numel</span><span class="p">(),</span> <span class="bp">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">)</span>
        <span class="n">n_out_chunks</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_n_chunks</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_get_output_numel</span><span class="p">(</span><span class="nb">input</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">n_in_chunks</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">n_out_chunks</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">().</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        
        <span class="c1"># 입력과 가중치를 청크로 분할
</span>        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">input_shards</span> <span class="o">=</span> <span class="nb">input</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">n_in_chunks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">n_out_chunks</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">n_out_chunks</span><span class="p">)):</span>
            <span class="n">weight_shards</span> <span class="o">=</span> <span class="n">weight</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">n_in_chunks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">o</span> <span class="o">=</span> <span class="bp">None</span>
            
            <span class="c1"># 청크별로 컨볼루션 수행
</span>            <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_shards</span><span class="p">,</span> <span class="n">weight_shards</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">o</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="n">o</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">conv3d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">dilation</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">groups</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">o</span> <span class="o">+=</span> <span class="n">F</span><span class="p">.</span><span class="n">conv3d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">dilation</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">groups</span><span class="p">)</span>
            
            <span class="n">outputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>청크 기반 처리의 장점:</strong></p>
<ul>
  <li><strong>메모리 절약</strong>: 큰 텐서를 작은 조각으로 분할 처리</li>
  <li><strong>수치적 동등성</strong>: 표준 컨볼루션과 동일한 결과</li>
  <li><strong>자동 최적화</strong>: 메모리 상황에 따라 자동 전환</li>
</ul>

<h3 id="패딩-최적화">패딩 최적화</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">@</span><span class="n">torch</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s">"max-autotune-no-cudagraphs"</span><span class="p">,</span> <span class="n">dynamic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">pad_for_conv3d_kernel_3x3x3</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="s">"""3x3x3 커널을 위한 최적화된 패딩"""</span>
    <span class="n">n_chunks</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">/</span> <span class="n">NUMEL_LIMIT</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">n_chunks</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># 공간 차원 패딩 (상수값)
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s">"constant"</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># 시간 차원 패딩 (복제)
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s">"replicate"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># 청크별 처리
</span>        <span class="n">out_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">n_chunks</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">inp_chunk</span> <span class="ow">in</span> <span class="n">x</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">n_chunks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">out_chunk</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="n">inp_chunk</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s">"constant"</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">out_chunk</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="n">out_chunk</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s">"replicate"</span><span class="p">)</span>
            <span class="n">out_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">out_chunk</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span><span class="n">out_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>

<p><strong>패딩 전략:</strong></p>
<ul>
  <li><strong>공간 차원</strong>: <code class="language-plaintext highlighter-rouge">constant</code> 모드로 0 패딩 (경계 효과 최소화)</li>
  <li><strong>시간 차원</strong>: <code class="language-plaintext highlighter-rouge">replicate</code> 모드로 복제 (시간적 연속성 보장)</li>
  <li><strong>@torch.compile</strong>: 컴파일 최적화로 성능 향상</li>
</ul>

<h2 id="5-실제-성능-최적화-효과">5. 실제 성능 최적화 효과</h2>

<h3 id="메모리-사용량-비교">메모리 사용량 비교</h3>

<table>
  <thead>
    <tr>
      <th>기법</th>
      <th>표준 구현</th>
      <th>최적화 구현</th>
      <th>절약률</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Conv3D</strong></td>
      <td>8GB</td>
      <td>2GB</td>
      <td>75%</td>
    </tr>
    <tr>
      <td><strong>Attention</strong></td>
      <td>4GB</td>
      <td>1GB</td>
      <td>75%</td>
    </tr>
    <tr>
      <td><strong>전체 VAE</strong></td>
      <td>32GB</td>
      <td>12GB</td>
      <td>62.5%</td>
    </tr>
  </tbody>
</table>

<h3 id="처리-속도-향상">처리 속도 향상</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 벤치마크 결과 (768x768 비디오, 16프레임)
# 표준 구현: 45초, 32GB 메모리
# 최적화 구현: 38초, 12GB 메모리
# 개선: 15% 빠름, 62.5% 메모리 절약
</span></code></pre></div></div>

<h2 id="6-실무-활용-가이드">6. 실무 활용 가이드</h2>

<h3 id="vae-커스터마이징">VAE 커스터마이징</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 고해상도용 VAE 설정
</span><span class="n">high_res_config</span> <span class="o">=</span> <span class="n">AutoEncoderConfig</span><span class="p">(</span>
    <span class="n">resolution</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">ch</span><span class="o">=</span><span class="mi">192</span><span class="p">,</span>                    <span class="c1"># 더 많은 기본 채널
</span>    <span class="n">ch_mult</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>     <span class="c1"># 더 깊은 다운샘플링
</span>    <span class="n">num_res_blocks</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>         <span class="c1"># 더 많은 잔차 블록
</span>    <span class="n">z_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>             <span class="c1"># 더 풍부한 잠재 표현
</span>    <span class="n">scale_factor</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>        <span class="c1"># 조정된 스케일링
</span><span class="p">)</span>

<span class="c1"># 경량화 VAE 설정
</span><span class="n">lightweight_config</span> <span class="o">=</span> <span class="n">AutoEncoderConfig</span><span class="p">(</span>
    <span class="n">resolution</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">ch</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>                    <span class="c1"># 적은 채널 수
</span>    <span class="n">ch_mult</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>     <span class="c1"># 단순한 구조
</span>    <span class="n">num_res_blocks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>         <span class="c1"># 최소 잔차 블록
</span>    <span class="n">z_channels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>             <span class="c1"># 표준 잠재 크기
</span>    <span class="n">scale_factor</span><span class="o">=</span><span class="mf">0.18215</span><span class="p">,</span>     <span class="c1"># 표준 스케일링
</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="손실-함수-조합">손실 함수 조합</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CombinedVAELoss</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lpips</span> <span class="o">=</span> <span class="n">LPIPS</span><span class="p">()</span>  <span class="c1"># 지각적 손실
</span>        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">fake</span><span class="p">,</span> <span class="n">posterior</span><span class="p">,</span> <span class="n">global_step</span><span class="p">):</span>
        <span class="c1"># 재구성 손실
</span>        <span class="n">recon_loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">fake</span><span class="p">,</span> <span class="n">real</span><span class="p">)</span>
        
        <span class="c1"># 지각적 손실
</span>        <span class="n">lpips_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lpips</span><span class="p">(</span><span class="n">fake</span><span class="p">,</span> <span class="n">real</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
        
        <span class="c1"># KL 발산
</span>        <span class="n">kl_loss</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">.</span><span class="n">kl</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>
        
        <span class="c1"># 적응적 가중치
</span>        <span class="n">lpips_weight</span> <span class="o">=</span> <span class="n">adopt_weight</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">kl_weight</span> <span class="o">=</span> <span class="n">adopt_weight</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        
        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">recon_loss</span> <span class="o">+</span> <span class="n">lpips_weight</span> <span class="o">*</span> <span class="n">lpips_loss</span> <span class="o">+</span> <span class="n">kl_weight</span> <span class="o">*</span> <span class="n">kl_loss</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s">'total_loss'</span><span class="p">:</span> <span class="n">total_loss</span><span class="p">,</span>
            <span class="s">'recon_loss'</span><span class="p">:</span> <span class="n">recon_loss</span><span class="p">,</span>
            <span class="s">'lpips_loss'</span><span class="p">:</span> <span class="n">lpips_loss</span><span class="p">,</span>
            <span class="s">'kl_loss'</span><span class="p">:</span> <span class="n">kl_loss</span>
        <span class="p">}</span>
</code></pre></div></div>

<h2 id="결론">결론</h2>

<p>Open-Sora VAE의 소스코드 분석을 통해 다음과 같은 핵심 인사이트를 얻을 수 있습니다:</p>

<p><strong>아키텍처 설계:</strong></p>
<ul>
  <li><strong>모듈화</strong>: 각 컴포넌트의 명확한 역할 분리</li>
  <li><strong>확장성</strong>: 해상도와 품질에 따른 유연한 설정</li>
  <li><strong>안정성</strong>: 수치 안정성을 고려한 구현</li>
</ul>

<p><strong>성능 최적화:</strong></p>
<ul>
  <li><strong>메모리 효율성</strong>: 청크 기반 처리로 대폭 절약</li>
  <li><strong>계산 최적화</strong>: PyTorch 네이티브 함수 활용</li>
  <li><strong>컴파일 최적화</strong>: @torch.compile 데코레이터 활용</li>
</ul>

<p><strong>실무 적용성:</strong></p>
<ul>
  <li><strong>커스터마이징</strong>: 용도에 맞는 설정 조정 가능</li>
  <li><strong>확장성</strong>: 새로운 손실 함수나 모듈 추가 용이</li>
  <li><strong>디버깅</strong>: 명확한 구조로 문제 추적 쉬움</li>
</ul>

<p>이러한 구현 기법들은 다른 생성 모델 개발에도 직접 적용할 수 있는 범용적 기술들입니다. 다음 포스트에서는 텍스트 임베딩 시스템의 구현을 상세히 분석해보겠습니다.</p>

<hr />

<p><em>이 글이 도움이 되셨다면 공유해주세요! 궁금한 점이 있으시면 댓글로 남겨주시기 바랍니다.</em></p>

  </div>

  <footer class="post-footer">
    <div class="post-navigation"><div class="nav-previous">
        <a href="/ai-blog/2024/05/12/kag-solver-module-analysis/" rel="prev">
          <i class="icon-left-arrow"></i>
          <span class="nav-title">KAG Solver 모듈 심층 분석 - 지능형 추론 엔진과 질의 응답 시스템</span>
        </a>
      </div><div class="nav-next">
        <a href="/ai-blog/2024/06/03/opensora-model-architecture-analysis/" rel="next">
          <span class="nav-title">Open-Sora 모델 아키텍처 심층 분석: STDiT3, VAE, T5의 완벽 이해</span>
          <i class="icon-right-arrow"></i>
        </a>
      </div></div>
  </footer>
  </article></div>

    </section>
    <footer class="condensed">
      <ul class="social about-footer condensed"><a href="https://github.com/leeyonghe" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://www.linkedin.com/in/lee-yong-hee-18912454/" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><!----></ul><p class="about-footer condensed">&copy;
        2025</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </footer>
  </main>
  
  <script type="text/javascript" src="/ai-blog/assets/js/darkmode.js"></script>
  
  <script src="/ai-blog/assets/js/simple-jekyll-search.min.js"></script>
  <script src="/ai-blog/assets/js/search.js"></script>
  
</body>

</html>
