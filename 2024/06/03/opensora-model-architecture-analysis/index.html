<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

<!-- 기본 SEO 메타 태그 -->
<title>Open-Sora 모델 아키텍처 심층 분석: STDiT3, VAE, T5의 완벽 이해 | AI Development Blog</title>
<meta name="description" content="개요Open-Sora는 세 가지 핵심 컴포넌트로 구성된 복잡한 아키텍처를 가지고 있습니다. 이번 포스트에서는 각 컴포넌트의 구조와 역할, 그리고 서로 어떻게 상호작용하는지 상세히 분석해보겠습니다.전체 아키텍처 개요graph TB    subgraph &quot;Open-Sora Comple...">
<meta name="author" content="David Lee">
<meta name="keywords" content="opensora, transformer, vae, t5, stdit, diffusion-models, video-generation">

<!-- 정규 URL -->
<link rel="canonical" href="https://leeyonghe.github.io/ai-blog/2024/06/03/opensora-model-architecture-analysis/">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="article">
<meta property="og:title" content="Open-Sora 모델 아키텍처 심층 분석: STDiT3, VAE, T5의 완벽 이해">
<meta property="og:description" content="개요Open-Sora는 세 가지 핵심 컴포넌트로 구성된 복잡한 아키텍처를 가지고 있습니다. 이번 포스트에서는 각 컴포넌트의 구조와 역할, 그리고 서로 어떻게 상호작용하는지 상세히 분석해보겠습니다.전체 아키텍처 개요graph TB    subgraph &quot;Open-Sora Comple...">
<meta property="og:url" content="https://leeyonghe.github.io/ai-blog/2024/06/03/opensora-model-architecture-analysis/">
<meta property="og:site_name" content="AI Development Blog">

<meta property="og:image" content="https://leeyonghe.github.io/ai-blog/assets/images/opensora-architecture.png">

<meta property="og:locale" content="ko_KR">

<!-- Twitter Card -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="Open-Sora 모델 아키텍처 심층 분석: STDiT3, VAE, T5의 완벽 이해">
<meta name="twitter:description" content="개요Open-Sora는 세 가지 핵심 컴포넌트로 구성된 복잡한 아키텍처를 가지고 있습니다. 이번 포스트에서는 각 컴포넌트의 구조와 역할, 그리고 서로 어떻게 상호작용하는지 상세히 분석해보겠습니다.전체 아키텍처 개요graph TB    subgraph &quot;Open-Sora Comple...">

<meta name="twitter:image" content="https://leeyonghe.github.io/ai-blog/assets/images/opensora-architecture.png">



<!-- 검색 엔진 인증 메타 태그 -->



<!-- 언어 및 지역 설정 -->
<meta name="language" content="ko">
<meta name="geo.region" content="KR">
<meta name="geo.country" content="KR">

<!-- 추가 SEO 메타 태그 -->
<meta name="robots" content="index, follow">
<meta name="revisit-after" content="7 days">
<meta name="rating" content="general">

<!-- RSS 피드 -->
<link rel="alternate" type="application/rss+xml" title="AI Development Blog" href="https://leeyonghe.github.io/ai-blog/feed.xml">

<!-- 구조화된 데이터 (JSON-LD) -->
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Blog",
  "name": "AI Development Blog",
  "description": "AI 개발 및 프레임워크 분석을 다루는 기술 블로그입니다. Rust, Python, AI/ML 프로젝트의 심층 분석과 실무 경험을 공유합니다.
",
  "url": "https://leeyonghe.github.io/ai-blog",
  "author": {
    "@type": "Person",
    "name": "David Lee",
    "email": "lee.yonghee.dev@gmail.com"
  },
  "inLanguage": "ko",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "https://leeyonghe.github.io/ai-blog/search?q={search_term_string}",
    "query-input": "required name=search_term_string"
  }
}
</script>

<!-- 개별 포스트 구조화된 데이터 -->

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Open-Sora 모델 아키텍처 심층 분석: STDiT3, VAE, T5의 완벽 이해",
  "description": "개요

Open-Sora는 세 가지 핵심 컴포넌트로 구성된 복잡한 아키텍처를 가지고 있습니다. 이번 포스트에서는 각 컴포넌트의 구조와 역할, 그리고 서로 어떻게 상호작용하는지 상세히 분석해보겠습니다.

전체 아키텍처 개요


graph TB
    subgraph &quot;Open-Sor...",
  "image": "https://leeyonghe.github.io/ai-blog/assets/images/opensora-architecture.png",
  "author": {
    "@type": "Person",
    "name": "David Lee"
  },
  "publisher": {
    "@type": "Organization",
    "name": "AI Development Blog",
    "logo": {
      "@type": "ImageObject",
      "url": ""
    }
  },
  "datePublished": "2024-06-03T02:00:00+00:00",
  "dateModified": "2024-06-03T02:00:00+00:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://leeyonghe.github.io/ai-blog/2024/06/03/opensora-model-architecture-analysis/"
  },
  "url": "https://leeyonghe.github.io/ai-blog/2024/06/03/opensora-model-architecture-analysis/",
  "inLanguage": "ko",
  "keywords": ["opensora","transformer","vae","t5","stdit","diffusion-models","video-generation"],
  "articleSection": ["AI","Deep Learning","Computer Vision"]
}
</script>

<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">
<link rel="stylesheet" href="/ai-blog/assets/css/style.css">
<link rel="stylesheet" href="/ai-blog/assets/css/post-detail.css">
<style>
/* Post Detail Page Styling */
.post-container article {
  background: #fff;
  border-radius: 12px;
  box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
  padding: 40px;
  margin: 30px auto;
  max-width: 800px;
}

@media screen and (max-width: 768px) {
  .post-container article {
    margin: 20px;
    padding: 25px;
    border-radius: 8px;
  }
}

.post-container article .post-header {
  border-bottom: 2px solid #f5f5f5;
  padding-bottom: 25px;
  margin-bottom: 30px;
}

.post-container article .post-header .post-title {
  font-size: 2.2em;
  font-weight: 700;
  color: #2c3e50;
  line-height: 1.3;
  margin-bottom: 15px;
}

@media screen and (max-width: 768px) {
  .post-container article .post-header .post-title {
    font-size: 1.8em;
  }
}

.post-container article .post-header .post-meta {
  display: flex;
  align-items: center;
  gap: 20px;
  flex-wrap: wrap;
}

.post-container article .post-header .post-meta .post-date {
  display: flex;
  align-items: center;
  color: #666;
  font-size: 0.9em;
}

.post-container article .post-header .post-meta .post-date i {
  margin-right: 8px;
  color: #888;
}

.post-container article .post-header .post-meta .post-categories-wrapper {
  display: flex;
  align-items: center;
}

.post-container article .post-header .post-meta .post-categories-wrapper i {
  margin-right: 8px;
  color: #888;
}

.post-container article .post-header .post-meta .post-categories-wrapper .post-categories {
  display: flex;
  gap: 8px;
  list-style: none;
  margin: 0;
  padding: 0;
}

.post-container article .post-header .post-meta .post-categories-wrapper .post-categories li {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  padding: 4px 12px;
  border-radius: 20px;
  font-size: 0.8em;
  font-weight: 500;
  text-transform: capitalize;
}

.post-container article .post-content {
  font-size: 1.1em;
  line-height: 1.8;
  color: #333;
}

.post-container article .post-content p {
  margin-bottom: 1.2em;
}

.post-container article .post-content h1,
.post-container article .post-content h2,
.post-container article .post-content h3,
.post-container article .post-content h4,
.post-container article .post-content h5,
.post-container article .post-content h6 {
  color: #2c3e50;
  margin: 1.5em 0 0.8em 0;
  font-weight: 600;
}

.post-container article .post-content h2 {
  font-size: 1.8em;
  border-bottom: 2px solid #3498db;
  padding-bottom: 10px;
}

.post-container article .post-content h3 {
  font-size: 1.5em;
  color: #34495e;
}

.post-container article .post-content code {
  background: #f8f9fa;
  padding: 2px 6px;
  border-radius: 4px;
  font-size: 0.9em;
  color: #e74c3c;
}

.post-container article .post-content pre {
  background: #f8f9fa;
  border: 1px solid #e9ecef;
  border-radius: 6px;
  padding: 15px;
  overflow-x: auto;
  margin: 1.5em 0;
}

.post-container article .post-content pre code {
  background: none;
  color: #333;
  padding: 0;
}

.post-container article .post-content blockquote {
  border-left: 4px solid #3498db;
  background: #f8f9fa;
  padding: 15px 20px;
  margin: 1.5em 0;
  font-style: italic;
  color: #555;
}

.post-container article .post-content img {
  max-width: 100%;
  height: auto;
  border-radius: 8px;
  margin: 1.5em 0;
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
}

.post-container article .post-content ul,
.post-container article .post-content ol {
  padding-left: 1.5em;
  margin-bottom: 1.2em;
}

.post-container article .post-content ul li,
.post-container article .post-content ol li {
  margin-bottom: 0.5em;
}

.post-container article .post-content a {
  color: #3498db;
  text-decoration: none;
  border-bottom: 1px solid transparent;
  transition: all 0.3s ease;
}

.post-container article .post-content a:hover {
  border-bottom-color: #3498db;
}

.post-container article .post-footer {
  border-top: 2px solid #f5f5f5;
  padding-top: 25px;
  margin-top: 40px;
}

.post-container article .post-footer .post-navigation {
  display: flex;
  justify-content: space-between;
  align-items: center;
  gap: 20px;
}

@media screen and (max-width: 768px) {
  .post-container article .post-footer .post-navigation {
    flex-direction: column;
    gap: 15px;
  }
}

.post-container article .post-footer .post-navigation .nav-previous,
.post-container article .post-footer .post-navigation .nav-next {
  flex: 1;
}

.post-container article .post-footer .post-navigation .nav-previous a,
.post-container article .post-footer .post-navigation .nav-next a {
  display: flex;
  align-items: center;
  padding: 15px 20px;
  background: #f8f9fa;
  border-radius: 8px;
  text-decoration: none;
  color: #333;
  transition: all 0.3s ease;
  border: 2px solid transparent;
}

.post-container article .post-footer .post-navigation .nav-previous a:hover,
.post-container article .post-footer .post-navigation .nav-next a:hover {
  background: #e9ecef;
  border-color: #3498db;
  transform: translateY(-2px);
}

.post-container article .post-footer .post-navigation .nav-previous a i,
.post-container article .post-footer .post-navigation .nav-next a i {
  color: #3498db;
  margin: 0 8px;
}

.post-container article .post-footer .post-navigation .nav-previous a .nav-title,
.post-container article .post-footer .post-navigation .nav-next a .nav-title {
  font-weight: 500;
}

.post-container article .post-footer .post-navigation .nav-previous a {
  justify-content: flex-start;
}

.post-container article .post-footer .post-navigation .nav-next a {
  justify-content: flex-end;
  text-align: right;
}
</style>
<title>Open-Sora 모델 아키텍처 심층 분석: STDiT3, VAE, T5의 완벽 이해</title>

<script type="text/javascript" src="/ai-blog/assets/js/darkmode.js"></script>


<!-- Mermaid Diagram Support -->
<script type="text/javascript" src="/ai-blog/assets/js/mermaid-init.js"></script>
<link rel="stylesheet" href="/ai-blog/assets/css/network-diagrams.css">
<style>
/* Mermaid diagram styling - Network optimized */
.mermaid {
  text-align: center;
  margin: 2em 0;
  padding: 1.5em;
  background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
  border: 2px solid #e2e8f0;
  border-radius: 12px;
  box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
  overflow-x: auto;
  position: relative;
}

.mermaid::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  height: 4px;
  background: linear-gradient(90deg, #3b82f6, #1d4ed8, #1e40af);
  border-radius: 12px 12px 0 0;
}

.mermaid svg {
  max-width: 100%;
  height: auto;
  filter: drop-shadow(0 2px 4px rgba(0, 0, 0, 0.1));
}

/* Network diagram specific styling */
.mermaid .node rect,
.mermaid .node circle,
.mermaid .node ellipse,
.mermaid .node polygon {
  stroke-width: 2px;
  filter: drop-shadow(0 1px 3px rgba(0, 0, 0, 0.12));
}

.mermaid .edgePath path {
  stroke-width: 2px;
  filter: drop-shadow(0 1px 2px rgba(0, 0, 0, 0.1));
}

.mermaid .cluster rect {
  stroke-width: 2px;
  stroke-dasharray: 5,5;
  opacity: 0.9;
}

/* Enhanced error styling */
.mermaid-error {
  color: #dc2626;
  background: linear-gradient(135deg, #fef2f2 0%, #fee2e2 100%);
  border: 2px solid #fca5a5;
  border-radius: 12px;
  padding: 1.5em;
  text-align: center;
  font-style: italic;
  font-weight: 500;
  box-shadow: 0 4px 20px rgba(220, 38, 38, 0.1);
}

.mermaid-error::before {
  content: '⚠️ ';
  font-size: 1.2em;
  margin-right: 0.5em;
}

/* Loading animation */
.mermaid.loading {
  min-height: 200px;
  background: linear-gradient(
    90deg,
    #f1f5f9 25%,
    #e2e8f0 50%,
    #f1f5f9 75%
  );
  background-size: 200% 100%;
  animation: shimmer 2s infinite;
}

@keyframes shimmer {
  0% {
    background-position: -200% 0;
  }
  100% {
    background-position: 200% 0;
  }
}

/* Responsive Mermaid diagrams */
@media (max-width: 768px) {
  .mermaid {
    font-size: 0.85em;
    padding: 1em;
    margin: 1.5em 0;
    border-radius: 8px;
  }

  .mermaid svg {
    transform: scale(0.9);
    transform-origin: center;
  }
}

@media (max-width: 480px) {
  .mermaid {
    font-size: 0.75em;
    padding: 0.8em;
    margin: 1em 0;
  }

  .mermaid svg {
    transform: scale(0.8);
  }
}

/* Dark mode support */
@media (prefers-color-scheme: dark) {
  .mermaid {
    background: linear-gradient(135deg, #1e293b 0%, #334155 100%);
    border-color: #475569;
    color: #f1f5f9;
  }

  .mermaid::before {
    background: linear-gradient(90deg, #60a5fa, #3b82f6, #2563eb);
  }

  .mermaid-error {
    background: linear-gradient(135deg, #451a03 0%, #7c2d12 100%);
    border-color: #dc2626;
    color: #fef2f2;
  }
}

/* Print styles */
@media print {
  .mermaid {
    background: white !important;
    border: 1px solid #ccc !important;
    box-shadow: none !important;
    break-inside: avoid;
  }

  .mermaid::before {
    display: none !important;
  }
}
</style>
</head><body>
  <main class="container">
    <section class="about">
      <div class="about-header condensed">
      <div class="about-title">
      <a href="/ai-blog/">
        
        <img src="/ai-blog/assets/portfolio.png" alt="David Lee" />
        
      </a>
      <h2 id="title">
        <a href="/ai-blog/">David Lee</a>
      </h2>
      </div><p class="tagline">Developer</p></div>
      
      <ul class="social about-footer condensed"><a href="https://github.com/leeyonghe" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://www.linkedin.com/in/lee-yong-hee-18912454/" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><!----></ul><p class="about-footer condensed">&copy;
        2025</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </section>
    <section class="content">
      <style>
/* Post Detail Page Styling - Direct Inline */
.post-container article {
  background: #fff !important;
  border: none !important;
  border-top: none !important;
  border-right: none !important;
  border-bottom: none !important;
  border-left: none !important;
  border-width: 0 !important;
  border-style: none !important;
  outline: none !important;
  border-radius: 12px !important;
  box-shadow: none !important;
  padding: 40px !important;
  margin: 30px auto !important;
  max-width: 800px !important;
}

.post-container article .post-header .post-title {
  font-size: 2.2em !important;
  font-weight: 700 !important;
  color: #2c3e50 !important;
  line-height: 1.3 !important;
}

.post-container article .post-header {
  border-bottom: none !important;
  padding-bottom: 25px !important;
  margin-bottom: 30px !important;
}

.post-container article .post-content {
  font-size: 1.1em !important;
  line-height: 1.8 !important;
  color: #333 !important;
}

.post-container article .post-content h2 {
  font-size: 1.8em !important;
  border-bottom: none !important;
  padding-bottom: 10px !important;
  color: #2c3e50 !important;
}

.post-container article .post-header .post-meta .post-categories li {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
  color: white !important;
  padding: 4px 12px !important;
  border-radius: 20px !important;
  font-size: 0.8em !important;
  list-style: none !important;
  display: inline-block !important;
  margin-right: 8px !important;
}

.post-container article .post-footer {
  border-top: none !important;
  padding-top: 25px !important;
  margin-top: 40px !important;
}

/* 모든 border와 box-shadow 강제 제거 */
.post-container article *,
.post-container article *::before,
.post-container article *::after {
  border: none !important;
  border-top: none !important;
  border-right: none !important;
  border-bottom: none !important;
  border-left: none !important;
  border-width: 0 !important;
  border-style: none !important;
  outline: none !important;
  box-shadow: none !important;
}

/* 코드 블록과 pre 태그도 border, box-shadow 제거 */
.post-container article pre,
.post-container article code,
.post-container article .highlight,
.post-container article .highlighter-rouge {
  border: none !important;
  outline: none !important;
  box-shadow: none !important;
}
</style><div class="post-container">
  <article>
    <header class="post-header">
    <h1 class="post-title">Open-Sora 모델 아키텍처 심층 분석: STDiT3, VAE, T5의 완벽 이해</h1>
    <div class="post-meta">
      <div class="post-date">
        <i class="icon-calendar"></i>
        <time datetime="2024-06-03T02:00:00+00:00">Jun 3, 2024</time>
      </div><div class="post-categories-wrapper">
        <i class="icon-tag"></i>
        <ul class="post-categories"><li>AI</li><li>Deep Learning</li><li>Computer Vision</li></ul>
      </div></div>
  </header>

  <div class="post-content">
    <h2 id="개요">개요</h2>

<p>Open-Sora는 세 가지 핵심 컴포넌트로 구성된 복잡한 아키텍처를 가지고 있습니다. 이번 포스트에서는 각 컴포넌트의 구조와 역할, 그리고 서로 어떻게 상호작용하는지 상세히 분석해보겠습니다.</p>

<h2 id="전체-아키텍처-개요">전체 아키텍처 개요</h2>

<div class="mermaid">
graph TB
    subgraph "Open-Sora Complete Architecture"
        A[Text Input] --&gt; B[T5 Text Encoder]
        C[Video/Image Input] --&gt; D[VAE Encoder]
        
        B --&gt; E[Text Embeddings]
        D --&gt; F[Latent Representation]
        
        E --&gt; G[STDiT3 Transformer]
        F --&gt; G
        H[Noise] --&gt; G
        
        G --&gt; I[Denoised Latent]
        I --&gt; J[VAE Decoder]
        J --&gt; K[Generated Video/Image]
        
        subgraph "T5 Text Processing"
            B1[Tokenization]
            B2[Self-Attention]
            B3[Feed Forward]
            B4[Layer Norm]
            B --&gt; B1 --&gt; B2 --&gt; B3 --&gt; B4 --&gt; E
        end
        
        subgraph "VAE Processing"
            D1[Spatial Convolution]
            D2[Temporal Convolution]
            D3[Latent Distribution]
            D --&gt; D1 --&gt; D2 --&gt; D3 --&gt; F
            
            J1[Latent Sampling]
            J2[Spatial Deconvolution]
            J3[Temporal Deconvolution]
            I --&gt; J1 --&gt; J2 --&gt; J3 --&gt; K
        end
        
        subgraph "STDiT3 Diffusion"
            G1[Space-Time Attention]
            G2[Cross Attention]
            G3[MLP Blocks]
            G4[Adaptive Layer Norm]
            F --&gt; G1 --&gt; G2 --&gt; G3 --&gt; G4 --&gt; I
            E -.-&gt; G2
        end
    end
    
    style A fill:#e1f5fe
    style K fill:#c8e6c9
    style G fill:#ffcdd2
</div>

<p>Open-Sora는 다음 세 가지 주요 모델로 구성됩니다:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text Input → T5 Text Encoder → Text Embeddings
                                      ↓
Video/Image → VAE Encoder → Latent Space → STDiT3 Diffusion → Denoised Latent
                                                                      ↓
                                              VAE Decoder ← Generated Video/Image
</code></pre></div></div>

<h3 id="핵심-구성-요소">핵심 구성 요소</h3>

<ol>
  <li><strong>T5 Text Encoder</strong>: 텍스트 프롬프트를 임베딩으로 변환</li>
  <li><strong>VAE (Variational AutoEncoder)</strong>: 비디오/이미지를 잠재 공간으로 압축/복원</li>
  <li><strong>STDiT3 (Space-Time Diffusion Transformer)</strong>: 잠재 공간에서 확산 과정 수행</li>
</ol>

<h2 id="1-t5-text-encoder-분석">1. T5 Text Encoder 분석</h2>

<div class="mermaid">
graph TB
    subgraph "T5 Text Encoder Architecture"
        A[Text Input] --&gt; B[T5 Tokenizer]
        B --&gt; C[Token Embeddings]
        C --&gt; D[Positional Encoding]
        D --&gt; E[Encoder Stack]
        
        subgraph "T5 Encoder Layers"
            E --&gt; F[Self-Attention]
            F --&gt; G[Add &amp; Norm]
            G --&gt; H[Feed Forward]
            H --&gt; I[Add &amp; Norm]
            I --&gt; J[Next Layer]
        end
        
        J --&gt; K[Final Layer Norm]
        K --&gt; L[Text Embeddings Output]
        
        subgraph "Attention Mechanism"
            M[Query] 
            N[Key]
            O[Value]
            F --&gt; M
            F --&gt; N
            F --&gt; O
            M --&gt; P[Scaled Dot-Product]
            N --&gt; P
            O --&gt; P
        end
        
        subgraph "Configuration Options"
            Q[T5-Base: 12 layers]
            R[T5-Large: 24 layers]
            S[Max Length: 512 tokens]
            T[Multi-language Support]
        end
    end
    
    style A fill:#e1f5fe
    style L fill:#c8e6c9
    style F fill:#ffcdd2
</div>

<h3 id="구조-및-특징">구조 및 특징</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">@</span><span class="n">MODELS</span><span class="p">.</span><span class="n">register_module</span><span class="p">(</span><span class="s">"text_embedder"</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">HFEmbedder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">shardformer</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="o">**</span><span class="n">hf_kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">is_clip</span> <span class="o">=</span> <span class="s">"openai"</span> <span class="ow">in</span> <span class="n">from_pretrained</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">output_key</span> <span class="o">=</span> <span class="s">"pooler_output"</span> <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_clip</span> <span class="k">else</span> <span class="s">"last_hidden_state"</span>

        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_clip</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">:</span> <span class="n">CLIPTokenizer</span> <span class="o">=</span> <span class="n">CLIPTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">from_pretrained</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">hf_module</span><span class="p">:</span> <span class="n">CLIPTextModel</span> <span class="o">=</span> <span class="n">CLIPTextModel</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">from_pretrained</span><span class="p">,</span> <span class="o">**</span><span class="n">hf_kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">:</span> <span class="n">T5Tokenizer</span> <span class="o">=</span> <span class="n">T5Tokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span> <span class="n">legacy</span><span class="o">=</span><span class="bp">True</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">hf_module</span><span class="p">:</span> <span class="n">T5EncoderModel</span> <span class="o">=</span> <span class="n">T5EncoderModel</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">from_pretrained</span><span class="p">,</span> <span class="o">**</span><span class="n">hf_kwargs</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="t5-vs-clip-선택">T5 vs CLIP 선택</h3>

<p><strong>T5 선택 이유:</strong></p>
<ul>
  <li><strong>더 긴 시퀀스 처리</strong>: 복잡한 비디오 설명 가능</li>
  <li><strong>다국어 지원</strong>: 한국어 포함 다양한 언어</li>
  <li><strong>강력한 텍스트 이해</strong>: 문맥적 관계 파악</li>
</ul>

<h3 id="shardformer-최적화">Shardformer 최적화</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">shardformer_t5</span><span class="p">(</span><span class="n">t5</span><span class="p">:</span> <span class="n">T5EncoderModel</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T5EncoderModel</span><span class="p">:</span>
    <span class="s">"""T5 모델을 샤딩하여 최적화"""</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">t5</span><span class="p">.</span><span class="n">shared</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">dtype</span>
    <span class="n">shard_config</span> <span class="o">=</span> <span class="n">ShardConfig</span><span class="p">(</span>
        <span class="n">enable_tensor_parallelism</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>  <span class="c1"># 텐서 병렬화 비활성화
</span>        <span class="n">enable_jit_fused</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>           <span class="c1"># JIT 융합 최적화 활성화
</span>    <span class="p">)</span>
    <span class="n">shard_former</span> <span class="o">=</span> <span class="n">ShardFormer</span><span class="p">(</span><span class="n">shard_config</span><span class="o">=</span><span class="n">shard_config</span><span class="p">)</span>
    <span class="n">optim_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">shard_former</span><span class="p">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">t5</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">T5EncoderPolicy</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">optim_model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">).</span><span class="nb">eval</span><span class="p">().</span><span class="n">requires_grad_</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>최적화 효과:</strong></p>
<ul>
  <li><strong>JIT 융합</strong>: 연산 그래프 최적화로 속도 향상</li>
  <li><strong>메모리 효율성</strong>: 그래디언트 계산 비활성화</li>
  <li><strong>정밀도 보존</strong>: 원본 데이터 타입 유지</li>
</ul>

<h3 id="텍스트-처리-파이프라인">텍스트 처리 파이프라인</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">added_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">seq_align</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="c1"># 1. 토크나이징
</span>    <span class="n">batch_encoding</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">text</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">max_length</span><span class="p">,</span>
        <span class="n">return_length</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
        <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s">"max_length"</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># 2. 시퀀스 정렬 (배치 처리 최적화)
</span>    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">batch_encoding</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">added_tokens</span> <span class="o">+</span> <span class="n">seq_len</span><span class="p">)</span> <span class="o">%</span> <span class="n">seq_align</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">num_pad_tokens</span> <span class="o">=</span> <span class="n">seq_align</span> <span class="o">-</span> <span class="p">(</span><span class="n">added_tokens</span> <span class="o">+</span> <span class="n">seq_len</span><span class="p">)</span> <span class="o">%</span> <span class="n">seq_align</span>
        <span class="n">batch_encoding</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">batch_encoding</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">],</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_pad_tokens</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span>
        <span class="p">)</span>

    <span class="c1"># 3. 임베딩 생성
</span>    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">hf_module</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><span class="n">batch_encoding</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">hf_module</span><span class="p">.</span><span class="n">device</span><span class="p">),</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">output_key</span><span class="p">]</span>
</code></pre></div></div>

<h2 id="2-vae-variational-autoencoder-분석">2. VAE (Variational AutoEncoder) 분석</h2>

<h3 id="autoencoder-구성">AutoEncoder 구성</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">@</span><span class="n">dataclass</span>
<span class="k">class</span> <span class="nc">AutoEncoderConfig</span><span class="p">:</span>
    <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="bp">None</span>
    <span class="n">cache_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="bp">None</span>
    <span class="n">resolution</span><span class="p">:</span> <span class="nb">int</span>          <span class="c1"># 해상도
</span>    <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span>         <span class="c1"># 입력 채널 수
</span>    <span class="n">ch</span><span class="p">:</span> <span class="nb">int</span>                  <span class="c1"># 기본 채널 수
</span>    <span class="n">out_ch</span><span class="p">:</span> <span class="nb">int</span>             <span class="c1"># 출력 채널 수
</span>    <span class="n">ch_mult</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>      <span class="c1"># 채널 배수 (다운샘플링용)
</span>    <span class="n">num_res_blocks</span><span class="p">:</span> <span class="nb">int</span>     <span class="c1"># 잔차 블록 수
</span>    <span class="n">z_channels</span><span class="p">:</span> <span class="nb">int</span>         <span class="c1"># 잠재 공간 채널 수
</span>    <span class="n">scale_factor</span><span class="p">:</span> <span class="nb">float</span>     <span class="c1"># 스케일 팩터
</span>    <span class="n">shift_factor</span><span class="p">:</span> <span class="nb">float</span>     <span class="c1"># 시프트 팩터
</span>    <span class="n">sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span>     <span class="c1"># 샘플링 여부
</span></code></pre></div></div>

<h3 id="attention-block-구조">Attention Block 구조</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AttnBlock</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        
        <span class="c1"># Group Normalization
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">GroupNorm</span><span class="p">(</span>
            <span class="n">num_groups</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> 
            <span class="n">num_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> 
            <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> 
            <span class="n">affine</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>
        
        <span class="c1"># Query, Key, Value 프로젝션
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># 출력 프로젝션
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">proj_out</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>핵심 특징:</strong></p>
<ul>
  <li><strong>Self-Attention</strong>: 공간적 관계 학습</li>
  <li><strong>Group Normalization</strong>: 배치 크기에 무관한 정규화</li>
  <li><strong>1x1 Convolution</strong>: 효율적인 특징 변환</li>
</ul>

<h3 id="가우시안-분포-처리">가우시안 분포 처리</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DiagonalGaussianDistribution</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="n">parameters</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mean</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">logvar</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">logvar</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">logvar</span><span class="p">,</span> <span class="o">-</span><span class="mf">30.0</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="n">deterministic</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">logvar</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">logvar</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">deterministic</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">mean</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">mean</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">std</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mean</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>역할:</strong></p>
<ul>
  <li><strong>잠재 공간 샘플링</strong>: 확률적 인코딩</li>
  <li><strong>정규화</strong>: 잠재 벡터의 분포 제어</li>
  <li><strong>안정성</strong>: logvar 클램핑으로 수치 안정성</li>
</ul>

<h2 id="3-stdit3-space-time-diffusion-transformer">3. STDiT3 (Space-Time Diffusion Transformer)</h2>

<h3 id="아키텍처-개요">아키텍처 개요</h3>

<p>STDiT3는 Open-Sora의 핵심 생성 모델로, 다음과 같은 특징을 가집니다:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Gradio 앱에서의 STDiT3 로딩
</span><span class="kn">from</span> <span class="nn">opensora.models.stdit.stdit3</span> <span class="kn">import</span> <span class="n">STDiT3</span>

<span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">config</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">items</span><span class="p">()</span> 
                <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s">"type"</span><span class="p">,</span> <span class="s">"from_pretrained"</span><span class="p">,</span> <span class="s">"force_huggingface"</span><span class="p">)}</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Load STDIT3 from "</span><span class="p">,</span> <span class="n">weight_path</span><span class="p">)</span>
<span class="n">stdit</span> <span class="o">=</span> <span class="n">STDiT3</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">weight_path</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">).</span><span class="n">cuda</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="핵심-혁신-사항">핵심 혁신 사항</h3>

<h4 id="1-space-time-attention">1. Space-Time Attention</h4>
<ul>
  <li><strong>공간적 어텐션</strong>: 프레임 내 픽셀 간 관계</li>
  <li><strong>시간적 어텐션</strong>: 프레임 간 시간적 연속성</li>
  <li><strong>통합 처리</strong>: 3D 어텐션으로 효율적 처리</li>
</ul>

<h4 id="2-다중-해상도-지원">2. 다중 해상도 지원</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 해상도별 모델 가중치
</span><span class="n">HF_STDIT_MAP</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"t2v"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">"360p"</span><span class="p">:</span> <span class="s">"hpcaitech/OpenSora-STDiT-v4-360p"</span><span class="p">,</span>
        <span class="s">"720p"</span><span class="p">:</span> <span class="s">"hpcaitech/OpenSora-STDiT-v4"</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s">"i2v"</span><span class="p">:</span> <span class="s">"hpcaitech/OpenSora-STDiT-v4-i2v"</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<h4 id="3-조건부-생성">3. 조건부 생성</h4>
<ul>
  <li><strong>텍스트 조건</strong>: T5 임베딩 활용</li>
  <li><strong>이미지 조건</strong>: 첫 프레임 고정</li>
  <li><strong>모션 점수</strong>: 동작 강도 제어</li>
</ul>

<h3 id="확산-과정-diffusion-process">확산 과정 (Diffusion Process)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 샘플링 과정
</span><span class="n">samples</span> <span class="o">=</span> <span class="n">scheduler</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span>
    <span class="n">stdit</span><span class="p">,</span>                    <span class="c1"># STDiT3 모델
</span>    <span class="n">text_encoder</span><span class="p">,</span>            <span class="c1"># T5 텍스트 인코더
</span>    <span class="n">z</span><span class="o">=</span><span class="n">z</span><span class="p">,</span>                     <span class="c1"># 초기 노이즈
</span>    <span class="n">z_cond</span><span class="o">=</span><span class="n">ref</span><span class="p">,</span>              <span class="c1"># 조건부 잠재 벡터
</span>    <span class="n">z_cond_mask</span><span class="o">=</span><span class="n">x_cond_mask</span><span class="p">,</span> <span class="c1"># 조건부 마스크
</span>    <span class="n">prompts</span><span class="o">=</span><span class="n">batch_prompts_loop</span><span class="p">,</span>  <span class="c1"># 배치 프롬프트
</span>    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="n">additional_args</span><span class="o">=</span><span class="n">model_args</span><span class="p">,</span>
    <span class="n">progress</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
    <span class="n">mask_index</span><span class="o">=</span><span class="n">mask_index</span><span class="p">,</span>
    <span class="n">image_cfg_scale</span><span class="o">=</span><span class="n">image_cfg_scale</span><span class="p">,</span>
    <span class="n">use_sdedit</span><span class="o">=</span><span class="n">use_sdedit</span><span class="p">,</span>
    <span class="n">use_oscillation_guidance_for_text</span><span class="o">=</span><span class="n">use_oscillation_guidance_for_text</span><span class="p">,</span>
    <span class="n">use_oscillation_guidance_for_image</span><span class="o">=</span><span class="n">use_oscillation_guidance_for_image</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<h2 id="모델-간-상호작용">모델 간 상호작용</h2>

<h3 id="1-텍스트--비디오-생성-파이프라인">1. 텍스트 → 비디오 생성 파이프라인</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">build_models</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">resolution</span><span class="p">,</span> <span class="n">enable_optimization</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="s">"""모델 구축 및 초기화"""</span>
    
    <span class="c1"># 1. VAE 구축
</span>    <span class="n">vae</span> <span class="o">=</span> <span class="n">build_module</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">vae</span><span class="p">,</span> <span class="n">MODELS</span><span class="p">).</span><span class="n">cuda</span><span class="p">()</span>
    
    <span class="c1"># 2. 텍스트 인코더 구축
</span>    <span class="n">text_encoder</span> <span class="o">=</span> <span class="n">build_module</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">text_encoder</span><span class="p">,</span> <span class="n">MODELS</span><span class="p">)</span>
    <span class="n">text_encoder</span><span class="p">.</span><span class="n">t5</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">text_encoder</span><span class="p">.</span><span class="n">t5</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
    
    <span class="c1"># 3. STDiT3 구축
</span>    <span class="n">stdit</span> <span class="o">=</span> <span class="n">STDiT3</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">weight_path</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">).</span><span class="n">cuda</span><span class="p">()</span>
    
    <span class="c1"># 4. 스케줄러 구축
</span>    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">build_module</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="n">SCHEDULERS</span><span class="p">)</span>
    
    <span class="c1"># 5. CFG를 위한 임베더 연결
</span>    <span class="n">text_encoder</span><span class="p">.</span><span class="n">y_embedder</span> <span class="o">=</span> <span class="n">stdit</span><span class="p">.</span><span class="n">y_embedder</span>
    
    <span class="c1"># 6. 최적화 및 평가 모드
</span>    <span class="n">vae</span> <span class="o">=</span> <span class="n">vae</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span><span class="p">).</span><span class="nb">eval</span><span class="p">()</span>
    <span class="n">text_encoder</span><span class="p">.</span><span class="n">t5</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">text_encoder</span><span class="p">.</span><span class="n">t5</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="n">stdit</span> <span class="o">=</span> <span class="n">stdit</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span><span class="p">).</span><span class="nb">eval</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">vae</span><span class="p">,</span> <span class="n">text_encoder</span><span class="p">,</span> <span class="n">stdit</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">config</span>
</code></pre></div></div>

<h3 id="2-이미지--비디오-생성-파이프라인">2. 이미지 → 비디오 생성 파이프라인</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 참조 이미지 처리
</span><span class="n">refs</span> <span class="o">=</span> <span class="n">collect_references_batch</span><span class="p">(</span><span class="n">refs</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)</span>

<span class="c1"># 조건부 참조 준비
</span><span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"i2v"</span><span class="p">:</span>
    <span class="n">image_cfg_scale</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"image_cfg_scale"</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">)</span>
    <span class="n">ref</span><span class="p">,</span> <span class="n">mask_index</span> <span class="o">=</span> <span class="n">prep_ref_and_mask</span><span class="p">(</span>
        <span class="n">cond_type</span><span class="p">,</span> <span class="n">condition_frame_length</span><span class="p">,</span> <span class="n">refs</span><span class="p">,</span> <span class="n">target_shape</span><span class="p">,</span> 
        <span class="n">num_loop</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dtype</span>
    <span class="p">)</span>
</code></pre></div></div>

<h2 id="성능-최적화-기법">성능 최적화 기법</h2>

<h3 id="1-메모리-최적화">1. 메모리 최적화</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 모델을 bfloat16으로 변환
</span><span class="n">vae</span> <span class="o">=</span> <span class="n">vae</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span><span class="p">).</span><span class="nb">eval</span><span class="p">()</span>
<span class="n">stdit</span> <span class="o">=</span> <span class="n">stdit</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span><span class="p">).</span><span class="nb">eval</span><span class="p">()</span>

<span class="c1"># T5는 fp32 유지 (정확도 보장)
</span><span class="n">text_encoder</span><span class="p">.</span><span class="n">t5</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">text_encoder</span><span class="p">.</span><span class="n">t5</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="2-분산-처리-지원">2. 분산 처리 지원</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 멀티 GPU 추론
</span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span> <span class="mi">8</span> <span class="o">--</span><span class="n">standalone</span> <span class="n">scripts</span><span class="o">/</span><span class="n">diffusion</span><span class="o">/</span><span class="n">inference</span><span class="p">.</span><span class="n">py</span> \
    <span class="n">configs</span><span class="o">/</span><span class="n">diffusion</span><span class="o">/</span><span class="n">inference</span><span class="o">/</span><span class="n">t2i2v_768px</span><span class="p">.</span><span class="n">py</span> \
    <span class="o">--</span><span class="n">save</span><span class="o">-</span><span class="nb">dir</span> <span class="n">samples</span> <span class="o">--</span><span class="n">prompt</span> <span class="s">"raining, sea"</span>
</code></pre></div></div>

<h3 id="3-동적-메모리-관리">3. 동적 메모리 관리</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># CUDA 메모리 정리
</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">empty_cache</span><span class="p">()</span>

<span class="c1"># 그래디언트 비활성화
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">inference_mode</span><span class="p">():</span>
    <span class="c1"># 추론 코드
</span>    <span class="k">pass</span>
</code></pre></div></div>

<h2 id="모델-크기-및-성능">모델 크기 및 성능</h2>

<h3 id="파라미터-수">파라미터 수</h3>
<ul>
  <li><strong>STDiT3</strong>: 11B 파라미터 (메인 생성 모델)</li>
  <li><strong>T5</strong>: 약 3B 파라미터 (텍스트 인코더)</li>
  <li><strong>VAE</strong>: 약 83M 파라미터 (인코더/디코더)</li>
</ul>

<h3 id="메모리-요구사항">메모리 요구사항</h3>
<ul>
  <li><strong>256x256 해상도</strong>: 최소 32GB GPU 메모리</li>
  <li><strong>768x768 해상도</strong>: 최소 80GB GPU 메모리 (A100 권장)</li>
</ul>

<h3 id="추론-시간">추론 시간</h3>
<ul>
  <li><strong>256x256, 5초 비디오</strong>: 약 60초 (H100 1GPU)</li>
  <li><strong>768x768, 5초 비디오</strong>: 약 276초 (H100 8GPU)</li>
</ul>

<h2 id="훈련-전략">훈련 전략</h2>

<h3 id="1-단계별-훈련">1. 단계별 훈련</h3>
<ol>
  <li><strong>VAE 사전 훈련</strong>: 이미지/비디오 압축 학습</li>
  <li><strong>텍스트 인코더 고정</strong>: T5 가중치 동결</li>
  <li><strong>STDiT3 훈련</strong>: 확산 과정 학습</li>
</ol>

<h3 id="2-다중-해상도-훈련">2. 다중 해상도 훈련</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 해상도별 점진적 학습
</span><span class="n">resolutions</span> <span class="o">=</span> <span class="p">[</span><span class="s">"144p"</span><span class="p">,</span> <span class="s">"360p"</span><span class="p">,</span> <span class="s">"720p"</span><span class="p">]</span>
<span class="k">for</span> <span class="n">resolution</span> <span class="ow">in</span> <span class="n">resolutions</span><span class="p">:</span>
    <span class="n">train_model</span><span class="p">(</span><span class="n">resolution</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="3-데이터-효율성">3. 데이터 효율성</h3>
<ul>
  <li><strong>캡션 품질</strong>: 고품질 텍스트-비디오 쌍</li>
  <li><strong>다양성</strong>: 다양한 장르와 스타일</li>
  <li><strong>길이 변화</strong>: 2초~15초 비디오</li>
</ul>

<h2 id="실제-활용-시나리오">실제 활용 시나리오</h2>

<h3 id="1-콘텐츠-제작">1. 콘텐츠 제작</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 소셜 미디어 숏폼 생성
</span><span class="n">prompt</span> <span class="o">=</span> <span class="s">"A cat playing with a ball in a sunny garden, cute and playful"</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">generate_video</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">aspect_ratio</span><span class="o">=</span><span class="s">"9:16"</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="s">"5s"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="2-영상-편집">2. 영상 편집</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 기존 이미지에서 비디오 생성
</span><span class="n">reference_image</span> <span class="o">=</span> <span class="n">load_image</span><span class="p">(</span><span class="s">"portrait.jpg"</span><span class="p">)</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s">"The person smiles and nods gently"</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">generate_video</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">reference_image</span><span class="o">=</span><span class="n">reference_image</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="3-프로토타이핑">3. 프로토타이핑</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 광고 컨셉 시각화
</span><span class="n">prompt</span> <span class="o">=</span> <span class="s">"Modern minimalist product showcase, elegant lighting"</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">generate_video</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="s">"720p"</span><span class="p">,</span> <span class="n">motion_score</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="결론">결론</h2>

<p>Open-Sora의 아키텍처는 <strong>모듈화</strong>와 <strong>최적화</strong>의 완벽한 조합입니다.</p>

<p><strong>핵심 장점:</strong></p>
<ul>
  <li><strong>분업화</strong>: 각 컴포넌트의 명확한 역할 분담</li>
  <li><strong>확장성</strong>: 해상도와 길이에 따른 유연한 스케일링</li>
  <li><strong>효율성</strong>: bfloat16, Flash Attention 등 최신 최적화 기법</li>
  <li><strong>범용성</strong>: 텍스트-투-비디오, 이미지-투-비디오 모두 지원</li>
</ul>

<p>이러한 설계 철학은 다른 멀티모달 생성 모델 개발에도 중요한 참고 자료가 될 것입니다. 다음 포스트에서는 Gradio를 활용한 웹 인터페이스 구현을 살펴보겠습니다.</p>

<hr />

<p><em>이 글이 도움이 되셨다면 공유해주세요! 궁금한 점이 있으시면 댓글로 남겨주시기 바랍니다.</em></p>

  </div>

  <footer class="post-footer">
    <div class="post-navigation"><div class="nav-previous">
        <a href="/ai-blog/2024/05/17/opensora-vae-implementation-analysis/" rel="prev">
          <i class="icon-left-arrow"></i>
          <span class="nav-title">Open-Sora VAE 모델 소스코드 심층 분석: AutoEncoder부터 Disc...</span>
        </a>
      </div><div class="nav-next">
        <a href="/ai-blog/2024/07/15/foundation-models-data-and-architecture/" rel="next">
          <span class="nav-title">파운데이션 모델 이해하기 (1부) - 학습 데이터와 모델 아키텍처 심층 분석</span>
          <i class="icon-right-arrow"></i>
        </a>
      </div></div>
  </footer>
  </article></div>

    </section>
    <footer class="condensed">
      <ul class="social about-footer condensed"><a href="https://github.com/leeyonghe" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://www.linkedin.com/in/lee-yong-hee-18912454/" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><!----></ul><p class="about-footer condensed">&copy;
        2025</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </footer>
  </main>
  
  <script type="text/javascript" src="/ai-blog/assets/js/darkmode.js"></script>
  
  <script src="/ai-blog/assets/js/simple-jekyll-search.min.js"></script>
  <script src="/ai-blog/assets/js/search.js"></script>
  
</body>

</html>
